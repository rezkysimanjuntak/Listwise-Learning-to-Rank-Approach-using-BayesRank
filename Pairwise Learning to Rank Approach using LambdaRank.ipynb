{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(object):\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_sizes=(100,), activation=('relu',), solver='adam'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : integer\n",
    "            Number of input features.\n",
    "        hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "            The ith element represents the number of neurons in the ith\n",
    "            hidden layer.\n",
    "        activation : tuple, length = n_layers - 2, default ('relu',)\n",
    "            The ith element represents activation function in the ith\n",
    "            hidden layer.\n",
    "        solver : {'adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', adamax},\n",
    "        default 'adam'\n",
    "            The solver for weight optimization.\n",
    "            - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
    "              by Kingma, Diederik, and Jimmy Ba\n",
    "        \"\"\"\n",
    "        if len(hidden_layer_sizes) != len(activation):\n",
    "            raise ValueError('hidden_layer_sizes and activation should have the same size.')\n",
    "        self.model = self._build_model(input_size, hidden_layer_sizes, activation)\n",
    "        self.model.compile(optimizer=solver, loss=\"binary_crossentropy\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_model(input_shape, hidden_layer_sizes, activation):\n",
    "        \"\"\"\n",
    "        Build Keras Ranker model (Ranknet / LambdaRank).\n",
    "        \"\"\"\n",
    "        # Neural network structure\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_layer_sizes)):\n",
    "            hidden_layers.append(Dense(hidden_layer_sizes[i], activation=activation[i], name=str(activation[i]) + '_layer' + str(i)))\n",
    "        h0 = Dense(1, activation='linear', name='Identity_layer')\n",
    "        input1 = Input(shape=(input_shape,), name='Input_layer1')\n",
    "        input2 = Input(shape=(input_shape,), name='Input_layer2')\n",
    "        x1 = input1\n",
    "        x2 = input2\n",
    "        for i in range(len(hidden_layer_sizes)):\n",
    "            x1 = hidden_layers[i](x1)\n",
    "            x2 = hidden_layers[i](x2)\n",
    "        x1 = h0(x1)\n",
    "        x2 = h0(x2)\n",
    "        # Subtract layer\n",
    "        subtracted = Subtract(name='Subtract_layer')([x1, x2])\n",
    "        # sigmoid\n",
    "        out = Activation('sigmoid', name='Activation_layer')(subtracted)\n",
    "        # build model\n",
    "        model = Model(inputs=[input1, input2], outputs=out)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def _CalcDCG(labels):\n",
    "        sumdcg = 0.0\n",
    "        for i in range(len(labels)):\n",
    "            rel = labels[i]\n",
    "            if rel != 0:\n",
    "                sumdcg += ((2 ** rel) - 1) / math.log2(i + 2)\n",
    "        return sumdcg\n",
    "\n",
    "    def _fetch_qid_data(self, y, qid, eval_at=None):\n",
    "        \"\"\"Fetch indices, relevances, idcg and dcg for each query id.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        eval_at: integer\n",
    "            The rank postion to evaluate dcg and idcg.\n",
    "        Returns\n",
    "        -------\n",
    "        qid2indices : array, shape (n_unique_qid,)\n",
    "            Start index for each qid.\n",
    "        qid2rel : array, shape (n_unique_qid,)\n",
    "            A list of target labels (relevances) for each qid.\n",
    "        qid2idcg: array, shape (n_unique_qid,)\n",
    "            Calculated idcg@eval_at for each qid.\n",
    "        qid2dcg: array, shape (n_unique_qid,)\n",
    "            Calculated dcg@eval_at for each qid.\n",
    "        \"\"\"\n",
    "        qid_unique, qid2indices, qid_inverse_indices = np.unique(qid, return_index=True, return_inverse=True)\n",
    "        # get item releveance for each query id\n",
    "        qid2rel = [[] for _ in range(len(qid_unique))]\n",
    "        for i, qid_unique_index in enumerate(qid_inverse_indices):\n",
    "            qid2rel[qid_unique_index].append(y[i])\n",
    "        # get dcg, idcg for each query id @eval_at\n",
    "        if eval_at:\n",
    "            qid2dcg = [self._CalcDCG(qid2rel[i][:eval_at]) for i in range(len(qid_unique))]\n",
    "            qid2idcg = [self._CalcDCG(sorted(qid2rel[i], reverse=True)[:eval_at]) for i in range(len(qid_unique))]\n",
    "        else:\n",
    "            qid2dcg = [self._CalcDCG(qid2rel[i]) for i in range(len(qid_unique))]\n",
    "            qid2idcg = [self._CalcDCG(sorted(qid2rel[i], reverse=True)) for i in range(len(qid_unique))]\n",
    "        return qid2indices, qid2rel, qid2idcg, qid2dcg\n",
    "\n",
    "\n",
    "    def _transform_pairwise(self, X, y, qid):\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, qid, batch_size=None, epochs=1, verbose=1, validation_split=0.0):\n",
    "        \"\"\"Transform data and fit model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        \"\"\"\n",
    "        X1_trans, X2_trans, y_trans, weight = self._transform_pairwise(X, y, qid)\n",
    "        self.model.fit([X1_trans, X2_trans], y_trans, sample_weight=weight, batch_size=batch_size, epochs=epochs,\n",
    "                       verbose=verbose, validation_split=validation_split)\n",
    "        fit_temp = self.evaluate(X, y, qid)\n",
    "        return fit_temp\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict output.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: array, shape (n_samples,)\n",
    "            Model prediction.\n",
    "        \"\"\"\n",
    "        ranker_output = K.function([self.model.layers[0].input], [self.model.layers[-3].get_output_at(0)])\n",
    "        return ranker_output([X])[0].ravel()\n",
    "\n",
    "    def evaluate(self, X, y, qid, eval_at=None):\n",
    "        \"\"\"Predict and evaluate ndcg@eval_at.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        eval_at: integer\n",
    "            The rank postion to evaluate NDCG.\n",
    "        Returns\n",
    "        -------\n",
    "        ndcg@eval_at: float\n",
    "        \"\"\"\n",
    "        ndcg_temp = []\n",
    "        y_pred = self.predict(X)\n",
    "        tmp = np.array(np.hstack([y.reshape(-1, 1), y_pred.reshape(-1, 1), qid.reshape(-1, 1)]))\n",
    "        tmp = tmp[np.lexsort((-tmp[:, 1], tmp[:, 2]))]\n",
    "        y_sorted = tmp[:, 0]\n",
    "        qid_sorted = tmp[:, 2]\n",
    "        ndcg = self._EvalNDCG(y_sorted, qid_sorted, eval_at)\n",
    "        if eval_at:\n",
    "            print('ndcg@' + str(eval_at) + ': ' + str(round(ndcg, 6)))\n",
    "        else:\n",
    "            print('ndcg: ' + str(round(ndcg, 6)))\n",
    "            ndcg_temp.append(ndcg)\n",
    "        return ndcg\n",
    "\n",
    "    def _EvalNDCG(self, y, qid, eval_at=None):\n",
    "        \"\"\"Evaluate ndcg@eval_at.\n",
    "        Calculated ndcg@n is consistent with ndcg@n- in xgboost.\n",
    "        \"\"\"\n",
    "        _, _, qid2idcg, qid2dcg = self._fetch_qid_data(y, qid, eval_at)\n",
    "        sumndcg = 0\n",
    "        count = 0.0\n",
    "        for qid_unique_idx in range(len(qid2idcg)):\n",
    "            count += 1\n",
    "            if qid2idcg[qid_unique_idx] == 0:\n",
    "                continue\n",
    "            idcg = qid2idcg[qid_unique_idx]\n",
    "            dcg = qid2dcg[qid_unique_idx]\n",
    "            sumndcg += dcg / idcg\n",
    "        return sumndcg / count\n",
    "\n",
    "class LambdaRank(Ranker):\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_sizes=(100,), activation=('relu',), solver='adam'):\n",
    "        super(LambdaRank, self).__init__(input_size, hidden_layer_sizes, activation, solver)\n",
    "\n",
    "    def _transform_pairwise(self, X, y, qid):\n",
    "        \"\"\"Transform data into lambdarank pairs with balanced labels\n",
    "        for binary classification.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X1_trans : array, shape (k, n_feaures)\n",
    "            Features of pair 1\n",
    "        X2_trans : array, shape (k, n_feaures)\n",
    "            Features of pair 2\n",
    "        weight: array, shape (k, n_faetures)\n",
    "            Sample weight lambda.\n",
    "        y_trans : array, shape (k,)\n",
    "            Output class labels, where classes have values {0, 1}\n",
    "        \"\"\"\n",
    "        qid2indices, qid2rel, qid2idcg, _ = self._fetch_qid_data(y, qid)\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        weight = []\n",
    "        Y = []\n",
    "        for qid_unique_idx in range(len(qid2indices)):\n",
    "            if qid2idcg[qid_unique_idx] == 0:\n",
    "                continue\n",
    "            IDCG = 1.0 / qid2idcg[qid_unique_idx]\n",
    "            rel_list = qid2rel[qid_unique_idx]\n",
    "            qid_start_idx = qid2indices[qid_unique_idx]\n",
    "            for pos_idx in range(len(rel_list)):\n",
    "                for neg_idx in range(len(rel_list)):\n",
    "                    if rel_list[pos_idx] <= rel_list[neg_idx]:\n",
    "                        continue\n",
    "                    # calculate lambda\n",
    "                    pos_loginv = 1.0 / math.log2(pos_idx + 2)\n",
    "                    neg_loginv = 1.0 / math.log2(neg_idx + 2)\n",
    "                    pos_label = rel_list[pos_idx]\n",
    "                    neg_label = rel_list[neg_idx]\n",
    "                    original = ((1 << pos_label) - 1) * pos_loginv + ((1 << neg_label) - 1) * neg_loginv\n",
    "                    changed = ((1 << neg_label) - 1) * pos_loginv + ((1 << pos_label) - 1) * neg_loginv\n",
    "                    delta = (original - changed) * IDCG\n",
    "                    if delta < 0:\n",
    "                        delta = -delta\n",
    "                    # balanced class\n",
    "                    if 1 != (-1) ** (qid_unique_idx + pos_idx + neg_idx):\n",
    "                        X1.append(X[qid_start_idx + pos_idx])\n",
    "                        X2.append(X[qid_start_idx + neg_idx])\n",
    "                        weight.append(delta)\n",
    "                        Y.append(1)\n",
    "                    else:\n",
    "                        X1.append(X[qid_start_idx + neg_idx])\n",
    "                        X2.append(X[qid_start_idx + pos_idx])\n",
    "                        weight.append(delta)\n",
    "                        Y.append(0)\n",
    "        return np.asarray(X1), np.asarray(X2), np.asarray(Y), np.asarray(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustLETOR(df):\n",
    "    df[96] = df[0]\n",
    "    df[0] = df[2]\n",
    "    df[2] = df[97]\n",
    "    drop_cols = list(range(1, 96, 2))\n",
    "    drop_cols.extend(range(97, 104))\n",
    "    df_adjusted = df.drop(drop_cols, 1)\n",
    "    df_adjusted.columns = list(range(0, 49))\n",
    "    df_adjusted[49] = df_adjusted[48] > 0\n",
    "    df_adjusted.infer_objects()\n",
    "    df_adjusted[49] = df_adjusted[49].apply(int)\n",
    "    return df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(Path):\n",
    "    df_raw = pd.read_csv(Path, \" |:\", header=None, engine='python')\n",
    "    df = adjustLETOR(df_raw)\n",
    "    return df\n",
    "\n",
    "def learn_to_rank(Path, epochs_val):\n",
    "    train_df = preprocessing_df(Path + \"train.txt\")\n",
    "    val_df = preprocessing_df(Path + \"vali.txt\")\n",
    "    test_df = preprocessing_df(Path + \"test.txt\")\n",
    "    X_train = train_df.iloc[:,2:48]\n",
    "    X_train = X_train.to_numpy()\n",
    "    Y_train = train_df.iloc[:,49]\n",
    "    Y_train = Y_train.to_numpy()\n",
    "    qid_train = train_df.iloc[:,:1]\n",
    "    qid_train = qid_train.to_numpy().flatten()\n",
    "    \n",
    "    # train model\n",
    "    ranker = LambdaRank(input_size=X_train.shape[1], hidden_layer_sizes=(16,8,), activation=('relu', 'relu',), solver='adam')\n",
    "    ndcg = ranker.fit(X_train, Y_train, qid_train, epochs=epochs_val)\n",
    "    y_pred = ranker.predict(X_train)\n",
    "    return ndcg\n",
    "\n",
    "def ndcg_eval(Path, eval_val):\n",
    "    train_df = preprocessing_df(Path + \"train.txt\")\n",
    "    val_df = preprocessing_df(Path + \"vali.txt\")\n",
    "    test_df = preprocessing_df(Path + \"test.txt\")\n",
    "    X_train = train_df.iloc[:,2:48]\n",
    "    X_train = X_train.to_numpy()\n",
    "    Y_train = train_df.iloc[:,49]\n",
    "    Y_train = Y_train.to_numpy()\n",
    "    qid_train = train_df.iloc[:,:1]\n",
    "    qid_train = qid_train.to_numpy().flatten()\n",
    "    \n",
    "    # evaluate model\n",
    "    ranker = LambdaRank(input_size=X_train.shape[1], hidden_layer_sizes=(16,8,), activation=('relu', 'relu',), solver='adam')\n",
    "    ndcg_eval = ranker.evaluate(X_train, Y_train, qid_train, eval_at=eval_val)\n",
    "    return ndcg_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1503/1503 [==============================] - 5s 2ms/step - loss: 0.0124\n",
      "Epoch 2/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0110\n",
      "Epoch 3/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0104\n",
      "Epoch 4/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0100\n",
      "Epoch 5/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0097\n",
      "Epoch 6/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0094\n",
      "Epoch 7/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0092A: 0s - loss: \n",
      "Epoch 8/100\n",
      "1503/1503 [==============================] - 4s 2ms/step - loss: 0.0090\n",
      "Epoch 9/100\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0088\n",
      "Epoch 10/100\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0087\n",
      "Epoch 11/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0085\n",
      "Epoch 12/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0084\n",
      "Epoch 13/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0083\n",
      "Epoch 14/100\n",
      "1503/1503 [==============================] - 4s 2ms/step - loss: 0.0082\n",
      "Epoch 15/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0081\n",
      "Epoch 16/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0081\n",
      "Epoch 17/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0080\n",
      "Epoch 18/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0079\n",
      "Epoch 19/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0078\n",
      "Epoch 20/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0078\n",
      "Epoch 21/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0077\n",
      "Epoch 22/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0076\n",
      "Epoch 23/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0076\n",
      "Epoch 24/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0075\n",
      "Epoch 25/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0074\n",
      "Epoch 26/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 27/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0074\n",
      "Epoch 28/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 29/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0073\n",
      "Epoch 30/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0072\n",
      "Epoch 31/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0072\n",
      "Epoch 32/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 33/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 34/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 35/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0070A: 0s - \n",
      "Epoch 36/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0070A: 0s - loss: 0.\n",
      "Epoch 37/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 38/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 39/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 40/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0068\n",
      "Epoch 41/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0068A\n",
      "Epoch 42/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0067\n",
      "Epoch 43/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0067\n",
      "Epoch 44/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0067\n",
      "Epoch 45/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 46/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 47/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 48/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 49/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 50/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0064\n",
      "Epoch 51/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 52/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 53/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0063\n",
      "Epoch 54/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 55/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 56/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 57/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 58/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 59/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 60/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 61/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 62/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 63/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 64/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 65/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 66/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0060\n",
      "Epoch 67/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 68/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 69/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 70/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 71/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 72/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 73/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 74/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0058\n",
      "Epoch 75/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0058\n",
      "Epoch 76/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0058\n",
      "Epoch 77/100\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0057A:\n",
      "Epoch 78/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 79/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0057A:\n",
      "Epoch 80/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 81/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0057A\n",
      "Epoch 82/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 83/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 84/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 85/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 86/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 87/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055A: \n",
      "Epoch 88/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 89/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 90/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 92/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 93/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 94/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 95/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 96/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 97/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 98/100\n",
      "1503/1503 [==============================] - 4s 2ms/step - loss: 0.0054\n",
      "Epoch 99/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 100/100\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "ndcg: 0.621774\n",
      "Epoch 1/100\n",
      "1359/1359 [==============================] - 5s 3ms/step - loss: 0.0130\n",
      "Epoch 2/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0116\n",
      "Epoch 3/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0111\n",
      "Epoch 4/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0107A: 1s - ETA: 0s - los\n",
      "Epoch 5/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0104A: 0s - l\n",
      "Epoch 6/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0101\n",
      "Epoch 7/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0099\n",
      "Epoch 8/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0096\n",
      "Epoch 9/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0094\n",
      "Epoch 10/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0092\n",
      "Epoch 11/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0090\n",
      "Epoch 12/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0088A: \n",
      "Epoch 13/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0086\n",
      "Epoch 14/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0085\n",
      "Epoch 15/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0083A: 0s - loss: 0.0\n",
      "Epoch 16/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0083\n",
      "Epoch 17/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0081\n",
      "Epoch 18/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0080\n",
      "Epoch 19/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0078\n",
      "Epoch 20/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0078\n",
      "Epoch 21/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0077\n",
      "Epoch 22/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0077\n",
      "Epoch 23/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0075\n",
      "Epoch 24/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0075\n",
      "Epoch 25/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 26/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0074A:\n",
      "Epoch 27/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0073\n",
      "Epoch 28/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0072\n",
      "Epoch 29/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0072A: 0s - loss: 0\n",
      "Epoch 30/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0071\n",
      "Epoch 31/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 32/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0070\n",
      "Epoch 33/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 34/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0069A: 0s - \n",
      "Epoch 35/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 36/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 37/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0068\n",
      "Epoch 38/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0068\n",
      "Epoch 39/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0068\n",
      "Epoch 40/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0067\n",
      "Epoch 41/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0067\n",
      "Epoch 42/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 43/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0066\n",
      "Epoch 44/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 45/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0066\n",
      "Epoch 46/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0065\n",
      "Epoch 47/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 48/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 49/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0065\n",
      "Epoch 50/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0064\n",
      "Epoch 51/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0063\n",
      "Epoch 52/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0063\n",
      "Epoch 53/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0063\n",
      "Epoch 54/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0063\n",
      "Epoch 55/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 56/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 57/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 58/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0062\n",
      "Epoch 59/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0061\n",
      "Epoch 60/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0061\n",
      "Epoch 61/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 62/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0061\n",
      "Epoch 63/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0060\n",
      "Epoch 64/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 65/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0060A: 0s - los\n",
      "Epoch 66/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 67/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0060\n",
      "Epoch 68/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0059A\n",
      "Epoch 69/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 70/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 71/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 72/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0058\n",
      "Epoch 73/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 74/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0058\n",
      "Epoch 75/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Epoch 76/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 77/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0057A: 0s - loss:\n",
      "Epoch 78/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 79/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 80/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0056\n",
      "Epoch 81/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 82/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0056\n",
      "Epoch 83/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0056A: 0s - loss: 0.00 - ETA: 0s - l\n",
      "Epoch 84/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0056\n",
      "Epoch 85/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 86/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 87/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0055\n",
      "Epoch 88/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0055A: 0s - loss: \n",
      "Epoch 89/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 90/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 92/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 93/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 94/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 95/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 96/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 97/100\n",
      "1359/1359 [==============================] - 3s 2ms/step - loss: 0.0053\n",
      "Epoch 98/100\n",
      "1359/1359 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 99/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 100/100\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "ndcg: 0.654353\n",
      "Epoch 1/100\n",
      "1279/1279 [==============================] - 5s 3ms/step - loss: 0.0121\n",
      "Epoch 2/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0102\n",
      "Epoch 3/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0097A: 0s - loss: 0.\n",
      "Epoch 4/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0095\n",
      "Epoch 5/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0093\n",
      "Epoch 6/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0090\n",
      "Epoch 7/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0089\n",
      "Epoch 8/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0086\n",
      "Epoch 9/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0085\n",
      "Epoch 10/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0083\n",
      "Epoch 11/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0082\n",
      "Epoch 12/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0079A: 0s - los\n",
      "Epoch 13/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0078\n",
      "Epoch 14/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0077\n",
      "Epoch 15/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0075\n",
      "Epoch 16/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0074\n",
      "Epoch 17/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 18/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0072A: 0s - loss:\n",
      "Epoch 19/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0072\n",
      "Epoch 20/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 21/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0070\n",
      "Epoch 22/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 23/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0069A\n",
      "Epoch 24/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0069\n",
      "Epoch 25/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0068\n",
      "Epoch 26/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0068\n",
      "Epoch 27/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0067\n",
      "Epoch 28/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0067\n",
      "Epoch 29/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0066A: 0s - lo\n",
      "Epoch 30/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0065\n",
      "Epoch 31/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0064\n",
      "Epoch 32/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0064\n",
      "Epoch 33/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0064\n",
      "Epoch 34/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0063\n",
      "Epoch 35/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0062\n",
      "Epoch 36/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0062\n",
      "Epoch 37/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0062\n",
      "Epoch 38/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0061\n",
      "Epoch 39/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0061\n",
      "Epoch 40/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0061\n",
      "Epoch 41/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0060A: 0s - los\n",
      "Epoch 42/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0059\n",
      "Epoch 43/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 44/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0059A: 0s - loss: 0\n",
      "Epoch 45/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0058\n",
      "Epoch 46/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 47/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 48/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0058\n",
      "Epoch 49/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 50/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 51/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 52/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0056\n",
      "Epoch 53/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 54/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0056A: 0s - loss: 0\n",
      "Epoch 55/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0056\n",
      "Epoch 56/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0056\n",
      "Epoch 57/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 0.005 - 3s 3ms/step - loss: 0.0056\n",
      "Epoch 58/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0055\n",
      "Epoch 59/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0055\n",
      "Epoch 60/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0055\n",
      "Epoch 61/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0055A: 0s - loss: 0.\n",
      "Epoch 62/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0055\n",
      "Epoch 63/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0055\n",
      "Epoch 64/100\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 65/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0055\n",
      "Epoch 66/100\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 0.005 - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 67/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 68/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 69/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 70/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 71/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 72/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 73/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 74/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0053\n",
      "Epoch 75/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 76/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0053 - ETA: 0s - lo\n",
      "Epoch 77/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 78/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 79/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 80/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 81/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 82/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 83/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0052\n",
      "Epoch 84/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 85/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0052\n",
      "Epoch 86/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 87/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 88/100\n",
      "1279/1279 [==============================] - 3s 2ms/step - loss: 0.0052\n",
      "Epoch 89/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 90/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 91/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0052\n",
      "Epoch 92/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 93/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 94/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 95/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0050A: 0s - loss: 0.005\n",
      "Epoch 96/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 97/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0050\n",
      "Epoch 98/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 100/100\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0050\n",
      "ndcg: 0.639651\n",
      "Epoch 1/100\n",
      "1364/1364 [==============================] - 4s 2ms/step - loss: 0.0113\n",
      "Epoch 2/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0100\n",
      "Epoch 3/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0096A: 0s - loss: 0.00\n",
      "Epoch 4/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0092A: 0s - loss: 0\n",
      "Epoch 5/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0089\n",
      "Epoch 6/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0086\n",
      "Epoch 7/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0084\n",
      "Epoch 8/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0082\n",
      "Epoch 9/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0080\n",
      "Epoch 10/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0078A: 0s - lo\n",
      "Epoch 11/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0076\n",
      "Epoch 12/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0075\n",
      "Epoch 13/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 14/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0073A: 0s - loss: 0.0\n",
      "Epoch 15/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0072\n",
      "Epoch 16/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 17/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 18/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 19/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0068\n",
      "Epoch 20/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0067\n",
      "Epoch 21/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0066\n",
      "Epoch 22/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 23/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0065\n",
      "Epoch 24/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0065A: 0s - l\n",
      "Epoch 25/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 26/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 27/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0062\n",
      "Epoch 28/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0061A:\n",
      "Epoch 29/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 30/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 31/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 32/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0060\n",
      "Epoch 33/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 34/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 35/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 36/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 37/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 38/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 39/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Epoch 40/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 41/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0055\n",
      "Epoch 42/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 43/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 44/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0054\n",
      "Epoch 45/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 46/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 47/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0054\n",
      "Epoch 48/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 49/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0053\n",
      "Epoch 50/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0053\n",
      "Epoch 51/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 52/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0052\n",
      "Epoch 53/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0052\n",
      "Epoch 54/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 55/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0051\n",
      "Epoch 56/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0052A: 0s - l\n",
      "Epoch 57/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 58/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0051\n",
      "Epoch 59/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0050\n",
      "Epoch 60/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 61/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 62/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0049\n",
      "Epoch 63/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0049A: 0s - loss: 0.004\n",
      "Epoch 64/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0050\n",
      "Epoch 65/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0048A: 0s - loss: \n",
      "Epoch 66/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0049\n",
      "Epoch 67/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 68/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0048A: 0s - loss:\n",
      "Epoch 69/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 70/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0049\n",
      "Epoch 71/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 72/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0047\n",
      "Epoch 73/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0047A: 0s - loss: 0.004\n",
      "Epoch 74/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0047\n",
      "Epoch 75/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0047\n",
      "Epoch 76/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0047\n",
      "Epoch 77/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0046\n",
      "Epoch 78/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0046\n",
      "Epoch 79/100\n",
      "1364/1364 [==============================] - ETA: 0s - loss: 0.004 - 4s 3ms/step - loss: 0.0047\n",
      "Epoch 80/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0046\n",
      "Epoch 81/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0046\n",
      "Epoch 82/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0046\n",
      "Epoch 83/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0046\n",
      "Epoch 84/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0045\n",
      "Epoch 85/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 86/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0046\n",
      "Epoch 87/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0045\n",
      "Epoch 88/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 89/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0044\n",
      "Epoch 90/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0044\n",
      "Epoch 91/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 92/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0044\n",
      "Epoch 93/100\n",
      "1364/1364 [==============================] - ETA: 0s - loss: 0.004 - 3s 2ms/step - loss: 0.0044\n",
      "Epoch 94/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0043\n",
      "Epoch 95/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0044A: \n",
      "Epoch 96/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0043\n",
      "Epoch 97/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0043\n",
      "Epoch 98/100\n",
      "1364/1364 [==============================] - 3s 3ms/step - loss: 0.0043\n",
      "Epoch 99/100\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0043A: 1s - loss: - ETA: 0s -\n",
      "Epoch 100/100\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.0042\n",
      "ndcg: 0.615033\n",
      "Epoch 1/100\n",
      "1450/1450 [==============================] - 5s 3ms/step - loss: 0.0121\n",
      "Epoch 2/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0109\n",
      "Epoch 3/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0104\n",
      "Epoch 4/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0100\n",
      "Epoch 5/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0097A: 1s - loss: 0.00 - ET - ETA: 0s - loss: 0.0\n",
      "Epoch 6/100\n",
      "1450/1450 [==============================] - 5s 3ms/step - loss: 0.0094\n",
      "Epoch 7/100\n",
      "1450/1450 [==============================] - ETA: 0s - loss: 0.009 - 5s 4ms/step - loss: 0.0091\n",
      "Epoch 8/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0090\n",
      "Epoch 9/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0088\n",
      "Epoch 10/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0086A: 0s - los\n",
      "Epoch 11/100\n",
      "1450/1450 [==============================] - 3s 2ms/step - loss: 0.0085\n",
      "Epoch 12/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0084\n",
      "Epoch 13/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0082A: 1s - los - E\n",
      "Epoch 14/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0081\n",
      "Epoch 15/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0080\n",
      "Epoch 16/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0079\n",
      "Epoch 17/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0078A: 1s\n",
      "Epoch 18/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0077\n",
      "Epoch 19/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0075\n",
      "Epoch 20/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0074\n",
      "Epoch 21/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0073\n",
      "Epoch 22/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0073\n",
      "Epoch 23/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 24/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0071\n",
      "Epoch 25/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 26/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 27/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0068\n",
      "Epoch 28/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 29/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0067ET - ETA: 0s - loss: \n",
      "Epoch 30/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0067\n",
      "Epoch 31/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0066\n",
      "Epoch 32/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0065\n",
      "Epoch 33/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0064A: 0s - loss: 0.0\n",
      "Epoch 34/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 35/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 36/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 37/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0062\n",
      "Epoch 38/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 39/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 40/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 41/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0061A: 0s\n",
      "Epoch 42/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 43/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 44/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 45/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 46/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0059\n",
      "Epoch 47/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 48/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 49/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 50/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 51/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 52/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 53/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 54/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 55/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 56/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 57/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 58/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0056\n",
      "Epoch 59/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0056\n",
      "Epoch 60/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 61/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 62/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 63/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 64/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 65/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 66/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 67/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 68/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 69/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0054\n",
      "Epoch 70/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 71/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 72/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 73/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 74/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 75/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 76/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 77/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 78/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 79/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0052\n",
      "Epoch 80/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 81/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0052\n",
      "Epoch 82/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 83/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 84/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 85/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 86/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 87/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 88/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 89/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 90/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0051\n",
      "Epoch 91/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0051A: 0s - loss: \n",
      "Epoch 92/100\n",
      "1450/1450 [==============================] - 4s 2ms/step - loss: 0.0051\n",
      "Epoch 93/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 94/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0049\n",
      "Epoch 96/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0051A: 0s\n",
      "Epoch 97/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0050A: 0s - loss: 0\n",
      "Epoch 98/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 100/100\n",
      "1450/1450 [==============================] - ETA: 0s - loss: 0.004 - 4s 3ms/step - loss: 0.0049\n",
      "ndcg: 0.59328\n"
     ]
    }
   ],
   "source": [
    "list_ndcg = []\n",
    "epochs = 100\n",
    "for idx in range(1,6):\n",
    "    directory = \"MQ2008/Fold\"+str(idx)+\"/\"\n",
    "    dir_ndcg = learn_to_rank(directory, epochs)\n",
    "    list_ndcg.append(dir_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Eval for fold1:\n",
      "ndcg@1: 0.286624\n",
      "ndcg@3: 0.273508\n",
      "ndcg@5: 0.413618\n",
      "ndcg@10: 0.46639\n",
      "NDCG Eval for fold2:\n",
      "ndcg@1: 0.146497\n",
      "ndcg@3: 0.410316\n",
      "ndcg@5: 0.172978\n",
      "ndcg@10: 0.424505\n",
      "NDCG Eval for fold3:\n",
      "ndcg@1: 0.216561\n",
      "ndcg@3: 0.337628\n",
      "ndcg@5: 0.245291\n",
      "ndcg@10: 0.396311\n",
      "NDCG Eval for fold4:\n",
      "ndcg@1: 0.218684\n",
      "ndcg@3: 0.34809\n",
      "ndcg@5: 0.213245\n",
      "ndcg@10: 0.412037\n",
      "NDCG Eval for fold5:\n",
      "ndcg@1: 0.163482\n",
      "ndcg@3: 0.170368\n",
      "ndcg@5: 0.322891\n",
      "ndcg@10: 0.395443\n"
     ]
    }
   ],
   "source": [
    "list_ndcg_eval = []\n",
    "list_eval = [1,3,5,10]\n",
    "temp = []\n",
    "for fold in range(1,6):\n",
    "    print(\"NDCG Eval for fold\" + str(fold) + \":\")\n",
    "    for idx in range(len(list_eval)):\n",
    "        directory = \"MQ2008/Fold\"+str(idx+1)+\"/\"\n",
    "        dir_ndcg = ndcg_eval(directory, list_eval[idx])\n",
    "        temp.append(dir_ndcg)\n",
    "list_ndcg_eval.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDGC for fold 1 :  0.622\n",
      "NDGC for fold 2 :  0.654\n",
      "NDGC for fold 3 :  0.64\n",
      "NDGC for fold 4 :  0.615\n",
      "NDGC for fold 5 :  0.593\n",
      "NDGC Average : 0.625\n",
      "------------------------------\n",
      "NDGC Evaluate for fold 1 :\n",
      "NDGC@1: 0.286624\n",
      "NDGC@3: 0.273508\n",
      "NDGC@5: 0.413618\n",
      "NDGC@10: 0.46639\n",
      "Average : 0.360035\n",
      "NDGC Evaluate for fold 2 :\n",
      "NDGC@1: 0.146497\n",
      "NDGC@3: 0.410316\n",
      "NDGC@5: 0.172978\n",
      "NDGC@10: 0.424505\n",
      "Average : 0.288574\n",
      "NDGC Evaluate for fold 3 :\n",
      "NDGC@1: 0.216561\n",
      "NDGC@3: 0.337628\n",
      "NDGC@5: 0.245291\n",
      "NDGC@10: 0.396311\n",
      "Average : 0.298948\n",
      "NDGC Evaluate for fold 4 :\n",
      "NDGC@1: 0.218684\n",
      "NDGC@3: 0.34809\n",
      "NDGC@5: 0.213245\n",
      "NDGC@10: 0.412037\n",
      "Average : 0.298014\n",
      "NDGC Evaluate for fold 5 :\n",
      "NDGC@1: 0.163482\n",
      "NDGC@3: 0.170368\n",
      "NDGC@5: 0.322891\n",
      "NDGC@10: 0.395443\n",
      "Average : 0.263046\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1,6):\n",
    "    print(\"NDGC for fold \" + str(idx) + \" : \", round(list_ndcg[idx-1], 3))\n",
    "print(\"NDGC Average : \" + str(round(sum(list_ndcg) / len(list_ndcg), 3)))\n",
    "print(\"------------------------------\")\n",
    "count = 0;\n",
    "num = 0;\n",
    "for fold in range(1,6):\n",
    "    temp = 0;\n",
    "    eval_num = 0;\n",
    "    print(\"NDGC Evaluate for fold \" + str(fold) + \" :\")\n",
    "    num += 4;\n",
    "    while(count != num):\n",
    "        print(\"NDGC@\" + str(list_eval[eval_num]) + \": \" + str(round(list_ndcg_eval[0][count], 6)))\n",
    "        temp = temp + list_ndcg_eval[0][count]\n",
    "        count+=1;\n",
    "        eval_num+=1;\n",
    "    print(\"Average : \" + str(round(temp/4, 6)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
