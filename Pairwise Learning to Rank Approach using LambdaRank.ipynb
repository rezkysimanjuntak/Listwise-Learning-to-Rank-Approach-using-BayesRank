{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(object):\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_sizes=(100,), activation=('relu',), solver='adam'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : integer\n",
    "            Number of input features.\n",
    "        hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "            The ith element represents the number of neurons in the ith\n",
    "            hidden layer.\n",
    "        activation : tuple, length = n_layers - 2, default ('relu',)\n",
    "            The ith element represents activation function in the ith\n",
    "            hidden layer.\n",
    "        solver : {'adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', adamax},\n",
    "        default 'adam'\n",
    "            The solver for weight optimization.\n",
    "            - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
    "              by Kingma, Diederik, and Jimmy Ba\n",
    "        \"\"\"\n",
    "        if len(hidden_layer_sizes) != len(activation):\n",
    "            raise ValueError('hidden_layer_sizes and activation should have the same size.')\n",
    "        self.model = self._build_model(input_size, hidden_layer_sizes, activation)\n",
    "        self.model.compile(optimizer=solver, loss=\"binary_crossentropy\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_model(input_shape, hidden_layer_sizes, activation):\n",
    "        \"\"\"\n",
    "        Build Keras Ranker model (Ranknet / LambdaRank).\n",
    "        \"\"\"\n",
    "        # Neural network structure\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_layer_sizes)):\n",
    "            hidden_layers.append(Dense(hidden_layer_sizes[i], activation=activation[i], name=str(activation[i]) + '_layer' + str(i)))\n",
    "        h0 = Dense(1, activation='linear', name='Identity_layer')\n",
    "        input1 = Input(shape=(input_shape,), name='Input_layer1')\n",
    "        input2 = Input(shape=(input_shape,), name='Input_layer2')\n",
    "        x1 = input1\n",
    "        x2 = input2\n",
    "        for i in range(len(hidden_layer_sizes)):\n",
    "            x1 = hidden_layers[i](x1)\n",
    "            x2 = hidden_layers[i](x2)\n",
    "        x1 = h0(x1)\n",
    "        x2 = h0(x2)\n",
    "        # Subtract layer\n",
    "        subtracted = Subtract(name='Subtract_layer')([x1, x2])\n",
    "        # sigmoid\n",
    "        out = Activation('sigmoid', name='Activation_layer')(subtracted)\n",
    "        # build model\n",
    "        model = Model(inputs=[input1, input2], outputs=out)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def _CalcDCG(labels):\n",
    "        sumdcg = 0.0\n",
    "        for i in range(len(labels)):\n",
    "            rel = labels[i]\n",
    "            if rel != 0:\n",
    "                sumdcg += ((2 ** rel) - 1) / math.log2(i + 2)\n",
    "        return sumdcg\n",
    "\n",
    "    def _fetch_qid_data(self, y, qid, eval_at=None):\n",
    "        \"\"\"Fetch indices, relevances, idcg and dcg for each query id.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        eval_at: integer\n",
    "            The rank postion to evaluate dcg and idcg.\n",
    "        Returns\n",
    "        -------\n",
    "        qid2indices : array, shape (n_unique_qid,)\n",
    "            Start index for each qid.\n",
    "        qid2rel : array, shape (n_unique_qid,)\n",
    "            A list of target labels (relevances) for each qid.\n",
    "        qid2idcg: array, shape (n_unique_qid,)\n",
    "            Calculated idcg@eval_at for each qid.\n",
    "        qid2dcg: array, shape (n_unique_qid,)\n",
    "            Calculated dcg@eval_at for each qid.\n",
    "        \"\"\"\n",
    "        qid_unique, qid2indices, qid_inverse_indices = np.unique(qid, return_index=True, return_inverse=True)\n",
    "        # get item releveance for each query id\n",
    "        qid2rel = [[] for _ in range(len(qid_unique))]\n",
    "        for i, qid_unique_index in enumerate(qid_inverse_indices):\n",
    "            qid2rel[qid_unique_index].append(y[i])\n",
    "        # get dcg, idcg for each query id @eval_at\n",
    "        if eval_at:\n",
    "            qid2dcg = [self._CalcDCG(qid2rel[i][:eval_at]) for i in range(len(qid_unique))]\n",
    "            qid2idcg = [self._CalcDCG(sorted(qid2rel[i], reverse=True)[:eval_at]) for i in range(len(qid_unique))]\n",
    "        else:\n",
    "            qid2dcg = [self._CalcDCG(qid2rel[i]) for i in range(len(qid_unique))]\n",
    "            qid2idcg = [self._CalcDCG(sorted(qid2rel[i], reverse=True)) for i in range(len(qid_unique))]\n",
    "        return qid2indices, qid2rel, qid2idcg, qid2dcg\n",
    "\n",
    "\n",
    "    def _transform_pairwise(self, X, y, qid):\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, qid, batch_size=None, epochs=1, verbose=1, validation_split=0.0):\n",
    "        \"\"\"Transform data and fit model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        \"\"\"\n",
    "        X1_trans, X2_trans, y_trans, weight = self._transform_pairwise(X, y, qid)\n",
    "        self.model.fit([X1_trans, X2_trans], y_trans, sample_weight=weight, batch_size=batch_size, epochs=epochs,\n",
    "                       verbose=verbose, validation_split=validation_split)\n",
    "        fit_temp = self.evaluate(X, y, qid)\n",
    "        return fit_temp\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict output.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: array, shape (n_samples,)\n",
    "            Model prediction.\n",
    "        \"\"\"\n",
    "        ranker_output = K.function([self.model.layers[0].input], [self.model.layers[-3].get_output_at(0)])\n",
    "        return ranker_output([X])[0].ravel()\n",
    "\n",
    "    def evaluate(self, X, y, qid, eval_at=None):\n",
    "        \"\"\"Predict and evaluate ndcg@eval_at.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        eval_at: integer\n",
    "            The rank postion to evaluate NDCG.\n",
    "        Returns\n",
    "        -------\n",
    "        ndcg@eval_at: float\n",
    "        \"\"\"\n",
    "        ndcg_temp = []\n",
    "        y_pred = self.predict(X)\n",
    "        tmp = np.array(np.hstack([y.reshape(-1, 1), y_pred.reshape(-1, 1), qid.reshape(-1, 1)]))\n",
    "        tmp = tmp[np.lexsort((-tmp[:, 1], tmp[:, 2]))]\n",
    "        y_sorted = tmp[:, 0]\n",
    "        qid_sorted = tmp[:, 2]\n",
    "        ndcg = self._EvalNDCG(y_sorted, qid_sorted, eval_at)\n",
    "        if eval_at:\n",
    "            print('ndcg@' + str(eval_at) + ': ' + str(ndcg))\n",
    "        else:\n",
    "            print('ndcg: ' + str(ndcg))\n",
    "            ndcg_temp.append(ndcg)\n",
    "        return ndcg\n",
    "\n",
    "    def _EvalNDCG(self, y, qid, eval_at=None):\n",
    "        \"\"\"Evaluate ndcg@eval_at.\n",
    "        Calculated ndcg@n is consistent with ndcg@n- in xgboost.\n",
    "        \"\"\"\n",
    "        _, _, qid2idcg, qid2dcg = self._fetch_qid_data(y, qid, eval_at)\n",
    "        sumndcg = 0\n",
    "        count = 0.0\n",
    "        for qid_unique_idx in range(len(qid2idcg)):\n",
    "            count += 1\n",
    "            if qid2idcg[qid_unique_idx] == 0:\n",
    "                continue\n",
    "            idcg = qid2idcg[qid_unique_idx]\n",
    "            dcg = qid2dcg[qid_unique_idx]\n",
    "            sumndcg += dcg / idcg\n",
    "        return sumndcg / count\n",
    "\n",
    "class LambdaRank(Ranker):\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_sizes=(100,), activation=('relu',), solver='adam'):\n",
    "        super(LambdaRank, self).__init__(input_size, hidden_layer_sizes, activation, solver)\n",
    "\n",
    "    def _transform_pairwise(self, X, y, qid):\n",
    "        \"\"\"Transform data into lambdarank pairs with balanced labels\n",
    "        for binary classification.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Features.\n",
    "        y : array, shape (n_samples,)\n",
    "            Target labels.\n",
    "        qid: array, shape (n_samples,)\n",
    "            Query id that represents the grouping of samples.\n",
    "        Returns\n",
    "        -------\n",
    "        X1_trans : array, shape (k, n_feaures)\n",
    "            Features of pair 1\n",
    "        X2_trans : array, shape (k, n_feaures)\n",
    "            Features of pair 2\n",
    "        weight: array, shape (k, n_faetures)\n",
    "            Sample weight lambda.\n",
    "        y_trans : array, shape (k,)\n",
    "            Output class labels, where classes have values {0, 1}\n",
    "        \"\"\"\n",
    "        qid2indices, qid2rel, qid2idcg, _ = self._fetch_qid_data(y, qid)\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        weight = []\n",
    "        Y = []\n",
    "        for qid_unique_idx in range(len(qid2indices)):\n",
    "            if qid2idcg[qid_unique_idx] == 0:\n",
    "                continue\n",
    "            IDCG = 1.0 / qid2idcg[qid_unique_idx]\n",
    "            rel_list = qid2rel[qid_unique_idx]\n",
    "            qid_start_idx = qid2indices[qid_unique_idx]\n",
    "            for pos_idx in range(len(rel_list)):\n",
    "                for neg_idx in range(len(rel_list)):\n",
    "                    if rel_list[pos_idx] <= rel_list[neg_idx]:\n",
    "                        continue\n",
    "                    # calculate lambda\n",
    "                    pos_loginv = 1.0 / math.log2(pos_idx + 2)\n",
    "                    neg_loginv = 1.0 / math.log2(neg_idx + 2)\n",
    "                    pos_label = rel_list[pos_idx]\n",
    "                    neg_label = rel_list[neg_idx]\n",
    "                    original = ((1 << pos_label) - 1) * pos_loginv + ((1 << neg_label) - 1) * neg_loginv\n",
    "                    changed = ((1 << neg_label) - 1) * pos_loginv + ((1 << pos_label) - 1) * neg_loginv\n",
    "                    delta = (original - changed) * IDCG\n",
    "                    if delta < 0:\n",
    "                        delta = -delta\n",
    "                    # balanced class\n",
    "                    if 1 != (-1) ** (qid_unique_idx + pos_idx + neg_idx):\n",
    "                        X1.append(X[qid_start_idx + pos_idx])\n",
    "                        X2.append(X[qid_start_idx + neg_idx])\n",
    "                        weight.append(delta)\n",
    "                        Y.append(1)\n",
    "                    else:\n",
    "                        X1.append(X[qid_start_idx + neg_idx])\n",
    "                        X2.append(X[qid_start_idx + pos_idx])\n",
    "                        weight.append(delta)\n",
    "                        Y.append(0)\n",
    "        return np.asarray(X1), np.asarray(X2), np.asarray(Y), np.asarray(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustLETOR(df):\n",
    "    df[96] = df[0]\n",
    "    df[0] = df[2]\n",
    "    df[2] = df[97]\n",
    "    drop_cols = list(range(1, 96, 2))\n",
    "    drop_cols.extend(range(97, 104))\n",
    "    df_adjusted = df.drop(drop_cols, 1)\n",
    "    df_adjusted.columns = list(range(0, 49))\n",
    "    df_adjusted[49] = df_adjusted[48] > 0\n",
    "    df_adjusted.infer_objects()\n",
    "    df_adjusted[49] = df_adjusted[49].apply(int)\n",
    "    return df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(Path):\n",
    "    df_raw = pd.read_csv(Path, \" |:\", header=None, engine='python')\n",
    "    df = adjustLETOR(df_raw)\n",
    "    return df\n",
    "\n",
    "def learn_to_rank(Path, epochs_val):\n",
    "    train_df = preprocessing_df(Path + \"train.txt\")\n",
    "    val_df = preprocessing_df(Path + \"vali.txt\")\n",
    "    test_df = preprocessing_df(Path + \"test.txt\")\n",
    "    X_train = train_df.iloc[:,2:48]\n",
    "    X_train = X_train.to_numpy()\n",
    "    Y_train = train_df.iloc[:,49]\n",
    "    Y_train = Y_train.to_numpy()\n",
    "    qid_train = train_df.iloc[:,:1]\n",
    "    qid_train = qid_train.to_numpy().flatten()\n",
    "    \n",
    "    # train model\n",
    "    ranker = LambdaRank(input_size=X_train.shape[1], hidden_layer_sizes=(16,8,), activation=('relu', 'relu',), solver='adam')\n",
    "    ndcg = ranker.fit(X_train, Y_train, qid_train, epochs=epochs_val)\n",
    "    y_pred = ranker.predict(X_train)\n",
    "    return ndcg\n",
    "\n",
    "def ndcg_eval(Path, eval_val):\n",
    "    train_df = preprocessing_df(Path + \"train.txt\")\n",
    "    val_df = preprocessing_df(Path + \"vali.txt\")\n",
    "    test_df = preprocessing_df(Path + \"test.txt\")\n",
    "    X_train = train_df.iloc[:,2:48]\n",
    "    X_train = X_train.to_numpy()\n",
    "    Y_train = train_df.iloc[:,49]\n",
    "    Y_train = Y_train.to_numpy()\n",
    "    qid_train = train_df.iloc[:,:1]\n",
    "    qid_train = qid_train.to_numpy().flatten()\n",
    "    \n",
    "    # evaluate model\n",
    "    ranker = LambdaRank(input_size=X_train.shape[1], hidden_layer_sizes=(16,8,), activation=('relu', 'relu',), solver='adam')\n",
    "    ndcg_eval = ranker.evaluate(X_train, Y_train, qid_train, eval_at=eval_val)\n",
    "    return ndcg_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0122\n",
      "Epoch 2/5\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0109A: 0s -\n",
      "Epoch 3/5\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0105\n",
      "Epoch 4/5\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0101\n",
      "Epoch 5/5\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 0.0098\n",
      "ndcg: 0.5748880181368702\n",
      "Epoch 1/5\n",
      "1359/1359 [==============================] - 5s 3ms/step - loss: 0.0129\n",
      "Epoch 2/5\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0115\n",
      "Epoch 3/5\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0110\n",
      "Epoch 4/5\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0106\n",
      "Epoch 5/5\n",
      "1359/1359 [==============================] - 4s 3ms/step - loss: 0.0104\n",
      "ndcg: 0.6050986062167453\n",
      "Epoch 1/5\n",
      "1279/1279 [==============================] - 5s 3ms/step - loss: 0.0120A: 0s - \n",
      "Epoch 2/5\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0105\n",
      "Epoch 3/5\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0100A: 0s\n",
      "Epoch 4/5\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 0.0098\n",
      "Epoch 5/5\n",
      "1279/1279 [==============================] - 3s 3ms/step - loss: 0.0095\n",
      "ndcg: 0.6001564358780641\n",
      "Epoch 1/5\n",
      "1364/1364 [==============================] - 5s 3ms/step - loss: 0.0116\n",
      "Epoch 2/5\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0101A: 0s - loss: 0.01\n",
      "Epoch 3/5\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0096\n",
      "Epoch 4/5\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0093\n",
      "Epoch 5/5\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 0.0090\n",
      "ndcg: 0.5670915651442661\n",
      "Epoch 1/5\n",
      "1450/1450 [==============================] - 5s 3ms/step - loss: 0.0119\n",
      "Epoch 2/5\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0108\n",
      "Epoch 3/5\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0102A: 0s - l\n",
      "Epoch 4/5\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0099\n",
      "Epoch 5/5\n",
      "1450/1450 [==============================] - 4s 3ms/step - loss: 0.0096\n",
      "ndcg: 0.5437057449486725\n"
     ]
    }
   ],
   "source": [
    "list_ndcg = []\n",
    "epochs = 5\n",
    "for idx in range(1,6):\n",
    "    directory = \"MQ2008/Fold\"+str(idx)+\"/\"\n",
    "    dir_ndcg = learn_to_rank(directory, epochs)\n",
    "    list_ndcg.append(dir_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Eval for fold1:\n",
      "ndcg@1: 0.17197452229299362\n",
      "ndcg@3: 0.2609337968578328\n",
      "ndcg@5: 0.36966646339211134\n",
      "ndcg@10: 0.3688230307598316\n",
      "NDCG Eval for fold2:\n",
      "ndcg@1: 0.28662420382165604\n",
      "ndcg@3: 0.36741360605509954\n",
      "ndcg@5: 0.4433940972500616\n",
      "ndcg@10: 0.4527724711928939\n",
      "NDCG Eval for fold3:\n",
      "ndcg@1: 0.14012738853503184\n",
      "ndcg@3: 0.35673311844196365\n",
      "ndcg@5: 0.24145519084343575\n",
      "ndcg@10: 0.45511303224601674\n",
      "NDCG Eval for fold4:\n",
      "ndcg@1: 0.13800424628450106\n",
      "ndcg@3: 0.28762830970463577\n",
      "ndcg@5: 0.18690519785799095\n",
      "ndcg@10: 0.44753609125776045\n",
      "NDCG Eval for fold5:\n",
      "ndcg@1: 0.06157112526539278\n",
      "ndcg@3: 0.355936695144012\n",
      "ndcg@5: 0.2705458672705965\n",
      "ndcg@10: 0.3324718774390957\n"
     ]
    }
   ],
   "source": [
    "list_ndcg_eval = []\n",
    "list_eval = [1,3,5,10]\n",
    "temp = []\n",
    "for fold in range(1,6):\n",
    "    print(\"NDCG Eval for fold\" + str(fold) + \":\")\n",
    "    for idx in range(len(list_eval)):\n",
    "        directory = \"MQ2008/Fold\"+str(idx+1)+\"/\"\n",
    "        dir_ndcg = ndcg_eval(directory, list_eval[idx])\n",
    "        temp.append(dir_ndcg)\n",
    "list_ndcg_eval.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDGC for fold 1 :  0.575\n",
      "NDGC for fold 2 :  0.605\n",
      "NDGC for fold 3 :  0.6\n",
      "NDGC for fold 4 :  0.567\n",
      "NDGC for fold 5 :  0.544\n",
      "NDGC Average : 0.578\n",
      "------------------------------\n",
      "NDGC Evaluate for fold 1 :\n",
      "NDGC@1: 0.172\n",
      "NDGC@3: 0.261\n",
      "NDGC@5: 0.37\n",
      "NDGC@10: 0.369\n",
      "NDGC Evaluate for fold 2 :\n",
      "NDGC@1: 0.287\n",
      "NDGC@3: 0.367\n",
      "NDGC@5: 0.443\n",
      "NDGC@10: 0.453\n",
      "NDGC Evaluate for fold 3 :\n",
      "NDGC@1: 0.14\n",
      "NDGC@3: 0.357\n",
      "NDGC@5: 0.241\n",
      "NDGC@10: 0.455\n",
      "NDGC Evaluate for fold 4 :\n",
      "NDGC@1: 0.138\n",
      "NDGC@3: 0.288\n",
      "NDGC@5: 0.187\n",
      "NDGC@10: 0.448\n",
      "NDGC Evaluate for fold 5 :\n",
      "NDGC@1: 0.062\n",
      "NDGC@3: 0.356\n",
      "NDGC@5: 0.271\n",
      "NDGC@10: 0.332\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1,6):\n",
    "    print(\"NDGC for fold \" + str(idx) + \" : \", round(list_ndcg[idx-1], 3))\n",
    "print(\"NDGC Average : \" + str(round(sum(list_ndcg) / len(list_ndcg), 3)))\n",
    "print(\"------------------------------\")\n",
    "count = 0;\n",
    "num = 0;\n",
    "eval_num  = 0;\n",
    "for fold in range(1,6):\n",
    "    eval_num = 0;\n",
    "    print(\"NDGC Evaluate for fold \" + str(fold) + \" :\")\n",
    "    num += 4;\n",
    "    while(count != num):\n",
    "        print(\"NDGC@\" + str(list_eval[eval_num]) + \": \" + str(round(list_ndcg_eval[0][count], 3)))\n",
    "        count+=1;\n",
    "        eval_num+=1;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
